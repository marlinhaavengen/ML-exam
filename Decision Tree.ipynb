{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bf8f0d",
   "metadata": {},
   "source": [
    "# Machine Learning Final Exam -  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1d9c2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0d169bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('Habitable_Full_Balanced.csv')\n",
    "df_train = pd.read_csv('Habitable_Train_Balanced.csv')\n",
    "df_test = pd.read_csv('Habitable_Test.csv')\n",
    "df_val = pd.read_csv('Habitable_Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2cf8c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for df_full:\n",
      "Habitable\n",
      "0    5145\n",
      "1    1544\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for df_train:\n",
      "Habitable\n",
      "0    3608\n",
      "1    1082\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for df_test:\n",
      "Habitable\n",
      "0    770\n",
      "1     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for df_val:\n",
      "Habitable\n",
      "0    767\n",
      "1     14\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Value counts for df_full:\\n{df_full['Habitable'].value_counts()}\\n\")\n",
    "print(f\"Value counts for df_train:\\n{df_train['Habitable'].value_counts()}\\n\")\n",
    "print(f\"Value counts for df_test:\\n{df_test['Habitable'].value_counts()}\\n\")\n",
    "print(f\"Value counts for df_val:\\n{df_val['Habitable'].value_counts()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141378a",
   "metadata": {},
   "source": [
    "**Preparation:**\n",
    "\n",
    "Four files were imported. A training file that was already balanced in advance with synthetic data by SMOTE and a test and validation file, both of which contain the original, unbalanced data so as not to generate bias. In addition, an entire file containing balanced data using SMOTE was imported, which is used to perform cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76bbe9",
   "metadata": {},
   "source": [
    "## Overview of Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d4a0cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ecabb1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "ccp_alpha: 0.0\n",
      "class_weight: None\n",
      "criterion: gini\n",
      "max_depth: None\n",
      "max_features: None\n",
      "max_leaf_nodes: None\n",
      "min_impurity_decrease: 0.0\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "min_weight_fraction_leaf: 0.0\n",
      "random_state: None\n",
      "splitter: best\n"
     ]
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "for param, value in model.get_params().items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a67ea",
   "metadata": {},
   "source": [
    "### Overview of Decision Tree Parameters:\n",
    "\n",
    "**ccp_alpha:** This is the complexity parameter used for Minimal Cost-Complexity Pruning (CCP). It specifies the non-negative cost complexity parameter of the Decision Tree. Increasing ccp_alpha increases the pruning strength, potentially resulting in a simpler tree that generalizes better to unseen data.\n",
    "\n",
    "\n",
    "**class_weight:** This parameter allows you to specify weights for each class in the input data. It can be used to address class imbalance by giving more weight to minority classes, thereby affecting the impurity calculation during tree construction and potentially improving model performance on imbalanced datasets.\n",
    "\n",
    "**criterion:** This specifies the function to measure the quality of a split. It can take two values: 'gini' for the Gini impurity and 'entropy' for the information gain. These criteria determine how the decision tree selects the best feature to split on at each node.\n",
    "\n",
    "\n",
    "**max_depth:** This parameter specifies the maximum depth of the decision tree. If set to None (default), nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "\n",
    "**max_features:** This parameter specifies the number of features to consider when looking for the best split. It can take various values like 'auto', 'sqrt', 'log2', or an integer. If set to None (default), all features will be considered for splitting at each node.\n",
    "\n",
    "\n",
    "**max_leaf_nodes:** This parameter specifies the maximum number of leaf nodes in the decision tree. If set, the tree will be pruned such that it has no more than this number of leaf nodes.\n",
    "\n",
    "\n",
    "**min_impurity_decrease:** This parameter specifies a threshold for early stopping of tree growth. A split will only be considered if it induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "\n",
    "**min_samples_leaf:** This parameter specifies the minimum number of samples required to be at a leaf node. If set to an integer, it ensures that each leaf node has at least that number of samples.\n",
    "\n",
    "\n",
    "**min_samples_split:** This parameter specifies the minimum number of samples required to split an internal node. If set to an integer, it ensures that a node is split only if it contains at least that number of samples.\n",
    "\n",
    "\n",
    "**min_weight_fraction_leaf:** This parameter specifies the minimum weighted fraction of the total number of samples required to be at a leaf node. It works similarly to min_samples_leaf, but the samples are weighted.\n",
    "\n",
    "\n",
    "**random_state:** This parameter sets the seed for random number generation. It ensures reproducibility of the results.\n",
    "\n",
    "\n",
    "**splitter:** This parameter specifies the strategy used to choose the split at each node. It can take two values: 'best' to choose the best split based on the selected criterion, or 'random' to choose the best random split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c565c6",
   "metadata": {},
   "source": [
    "## 1. Default Model - All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "90c812a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train = df_train.drop(columns=['Habitable'])\n",
    "y_train = df_train['Habitable']\n",
    "\n",
    "\n",
    "X_test = df_test.drop(columns=['Habitable'])\n",
    "y_test = df_test['Habitable']\n",
    "\n",
    "X_val = df_val.drop(columns=['Habitable'])\n",
    "y_val = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a92049cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_default= DecisionTreeClassifier(random_state=42)\n",
    "model_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bec181e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for training set\n",
    "y_train_pred = model_default.predict(X_train)\n",
    "print(\"Training set classification report:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "183fcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation set\n",
    "y_val_pred = model_default.predict(X_val)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300f858",
   "metadata": {},
   "source": [
    "**Perfrom Cross-Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0403a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9779439835080932\n",
      "Recall: 0.9714290197062885\n",
      "F1 Score: 0.974636433430116\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1019    9]\n",
      " [  15  295]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9790732436472347\n",
      "Precision: 0.9672304506087612\n",
      "Recall: 0.9736873918354881\n",
      "F1 Score: 0.9704091723351352\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   17]\n",
      " [  11  293]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9865470852017937\n",
      "Precision: 0.9820831433348534\n",
      "Recall: 0.9798827386206027\n",
      "F1 Score: 0.980977325072587\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1022    8]\n",
      " [  10  298]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9872944693572496\n",
      "Precision: 0.9792851953541473\n",
      "Recall: 0.9848124300111982\n",
      "F1 Score: 0.9820135550707367\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1023   11]\n",
      " [   6  298]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9798055347793567\n",
      "Precision: 0.9689054423837032\n",
      "Recall: 0.9759352182741743\n",
      "F1 Score: 0.9723576936948526\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1002   17]\n",
      " [  10  308]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9829566226509385\n",
      "Mean Macro Precision across all folds: 0.9750896430379117\n",
      "Mean Macro Recall across all folds: 0.9771493596895505\n",
      "Mean Macro F1 Score across all folds: 0.9760788359206855\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "X_full = df_full.drop(columns=['Habitable'])\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "    \n",
    "    \n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "    \n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fe223",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "While the model demonstrates high accuracy on the training set, it struggles with generalization, as evidenced by the lower precision, recall, and F1 scores on the validation set and during cross-validation. This is expected in highly imbalanced datasets, where the model tends to favor the majority class and may struggle to accurately predict the minority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4b38e",
   "metadata": {},
   "source": [
    "## 2. Complexity Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b2fd01b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = model_default.feature_importances_\n",
    "features = X_train.columns\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(features)), importances[indices], align='center')\n",
    "plt.yticks(range(len(features)), np.array(features)[indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdc8c3",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "Analyzing the importance of the individual features in the decision tree model, we can see that some features have a greater influence on the classification than others. In particular, the features \"Distance\" and \"Orbital_Earth\" have a strong influence on the model, followed by \"Mass Earth\", \"Radius Earth\" and \"Stellar Magnitude\". \n",
    "The next step is to check how the model behaves when the complexity is reduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec880f",
   "metadata": {},
   "source": [
    "### Selecting the top 5 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e0b8b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_5 = df_train[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_train_5 = df_train['Habitable']\n",
    "\n",
    "X_test_5 = df_test[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_test_5 = df_test['Habitable']\n",
    "\n",
    "X_val_5 = df_val[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_val_5 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a2a827a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_five_features= DecisionTreeClassifier(random_state=42)\n",
    "model_five_features.fit(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "07b48ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for training set\n",
    "y_train_pred_5 = model_five_features.predict(X_train_5)\n",
    "print(\"Training set classification report:\")\n",
    "print(classification_report(y_train_5, y_train_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2c932900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation set\n",
    "y_val_pred_5 = model_five_features.predict(X_val_5)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val_5, y_val_pred_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c253842",
   "metadata": {},
   "source": [
    "**Perform Cross-Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "624fdd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6633ec",
   "metadata": {},
   "source": [
    "### Selecting the top 4 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e3e1ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_4 = df_train[['distance', 'orbital_radius', 'mass_earth', 'radius_earth']]\n",
    "y_train_4 = df_train['Habitable']\n",
    "\n",
    "X_test_4 = df_test[['distance', 'orbital_radius', 'mass_earth', 'radius_earth']]\n",
    "y_test_4 = df_test['Habitable']\n",
    "\n",
    "X_val_4 = df_val[['distance', 'orbital_radius', 'mass_earth', 'radius_earth']]\n",
    "y_val_4 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1d8066dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_four_features= DecisionTreeClassifier(random_state=42)\n",
    "model_four_features.fit(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "902649ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for training set\n",
    "y_train_pred_4 = model_four_features.predict(X_train_4)\n",
    "print(\"Training set classification report:\")\n",
    "print(classification_report(y_train_4, y_train_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5308f0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation set\n",
    "y_val_pred_4 = model_four_features.predict(X_val_4)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val_4, y_val_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76341e9b",
   "metadata": {},
   "source": [
    "**Perform Cross-Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "472dae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.972042913378344\n",
      "Mean Macro Precision across all folds: 0.9591296474169428\n",
      "Mean Macro Recall across all folds: 0.9625784855324573\n",
      "Mean Macro F1 Score across all folds: 0.9608257995356029\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3e20d",
   "metadata": {},
   "source": [
    "### Selecting the top 3 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "20f58966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_3 = df_train[['distance', 'orbital_radius', 'mass_earth']]\n",
    "y_train_3 = df_train['Habitable']\n",
    "\n",
    "X_test_3 = df_test[['distance', 'orbital_radius', 'mass_earth']]\n",
    "y_test_3 = df_test['Habitable']\n",
    "\n",
    "X_val_3 = df_val[['distance', 'orbital_radius', 'mass_earth']]\n",
    "y_val_3 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5096685f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_three_features= DecisionTreeClassifier(random_state=42)\n",
    "model_three_features.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5746d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for training set\n",
    "y_train_pred_3 = model_three_features.predict(X_train_3)\n",
    "print(\"Training set classification report:\")\n",
    "print(classification_report(y_train_3, y_train_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c347450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       767\n",
      "           1       0.28      0.50      0.36        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.64      0.74      0.67       781\n",
      "weighted avg       0.98      0.97      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation set\n",
    "y_val_pred_3 = model_three_features.predict(X_val_3)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val_3, y_val_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46963eee",
   "metadata": {},
   "source": [
    "**Perform Cross-Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1acb0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9680067035383637\n",
      "Mean Macro Precision across all folds: 0.9525053728534829\n",
      "Mean Macro Recall across all folds: 0.9581738911549957\n",
      "Mean Macro F1 Score across all folds: 0.9552783920693562\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf8e7c",
   "metadata": {},
   "source": [
    "### Model Selection: \n",
    "\n",
    "In evaluating the decision tree models with varying complexities resulting from different feature selections, several key observations emerge. Notably, when reducing the dimensionality of the feature space, we observe a notable improvement in precision, recall, and F1-score across the models with 5 and 4 features. This suggests that simplifying the model's input features leads to a more focused and effective decision-making process. On the other hand, when reducing the model's complexity too much (e.g. as seen with the 3 features), the performance decreases compared to the default model. \n",
    "\n",
    "Of particular significance is the performance of the model utilizing  five features. Despite the reduction in feature space, this model consistently achieves a high precision, recall, and F1-scores throughout all sets while maintaining a commendable level of accuracy. This outcome underscores the importance of feature selection in optimizing the model's predictive capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eef0ea",
   "metadata": {},
   "source": [
    "## 3. Model Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb1e2c",
   "metadata": {},
   "source": [
    "## 3.1 Class Weights\n",
    "This parameter allows you to specify weights for each class in the input data. It can be used to address class imbalance by giving more weight to minority classes, thereby affecting the impurity calculation during tree construction and potentially improving model performance on imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "55925b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 5}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 2}, {0: 1, 1: 5}, {0: 1, 1: 10}]  \n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8f84c",
   "metadata": {},
   "source": [
    "### 3.1.1 Class Weight Ratio: 1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a77eb6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with 1:2 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with 1:2 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the weight ratio (1:2 for minority:majority class)\n",
    "weight_ratio = {0: 1, 1: 2}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model_1_to_2 = DecisionTreeClassifier(random_state=42, class_weight=weight_ratio)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_1_to_2.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_1_to_2 = model_1_to_2.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set using the model with 1:2 weight ratio\n",
    "print(\"Training set classification report with 1:2 weight ratio:\")\n",
    "print(classification_report(y_train_5, y_train_pred_5))\n",
    "\n",
    "# Print classification report for validation set using the model with 1:2 weight ratio\n",
    "print(\"Validation set classification report with 1:2 weight ratio:\")\n",
    "print(classification_report(y_val_5, y_val_pred_1_to_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1f520eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9850495218865609\n",
      "Mean Macro Precision across all folds: 0.97721454165693\n",
      "Mean Macro Recall across all folds: 0.9809908558890428\n",
      "Mean Macro F1 Score across all folds: 0.9790633180550377\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Define the weight ratio (1:2 for minority:majority class)\n",
    "weight_ratio = {0: 1, 1: 2}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model = DecisionTreeClassifier(random_state=42, class_weight=weight_ratio)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977667cf",
   "metadata": {},
   "source": [
    "### 3.1.2 Class Weight Ratio: 1:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "edde732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with 1:5 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with 1:5 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.54      0.50      0.52        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.76      0.75      0.76       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the weight ratio (1:5 for minority:majority class)\n",
    "weight_ratio = {0: 1, 1: 5}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model_1_to_5 = DecisionTreeClassifier(random_state=42, class_weight=weight_ratio)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_1_to_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_1_to_5 = model_1_to_5.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set using the model with 1:5 weight ratio\n",
    "print(\"Training set classification report with 1:5 weight ratio:\")\n",
    "print(classification_report(y_train_5, y_train_pred_5))\n",
    "\n",
    "# Print classification report for validation set using the model with 1:5 weight ratio\n",
    "print(\"Validation set classification report with 1:5 weight ratio:\")\n",
    "print(classification_report(y_val_5, y_val_pred_1_to_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "69d1daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9853493699501259\n",
      "Mean Macro Precision across all folds: 0.9765541126349143\n",
      "Mean Macro Recall across all folds: 0.9825605244447931\n",
      "Mean Macro F1 Score across all folds: 0.9794844480620863\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Define the weight ratio \n",
    "weight_ratio = {0: 1, 1: 5}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model = DecisionTreeClassifier(random_state=42, class_weight=weight_ratio)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e87628",
   "metadata": {},
   "source": [
    "### 3.1.3 Class Weight Ratio: 1:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4e701b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with 1:10 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with 1:10 weight ratio:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.54      0.50      0.52        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.76      0.75      0.76       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the weight ratio (1:10 for minority:majority class)\n",
    "weight_ratio = {0: 1, 1: 10}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model_1_to_10 = DecisionTreeClassifier(random_state=42, class_weight=weight_ratio)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_1_to_10.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_1_to_10 = model_1_to_5.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set using the model with 1:10 weight ratio\n",
    "print(\"Training set classification report with 1:10 weight ratio:\")\n",
    "print(classification_report(y_train_5, y_train_pred_5))\n",
    "\n",
    "# Print classification report for validation set using the model with 1:10 weight ratio\n",
    "print(\"Validation set classification report with 1:10 weight ratio:\")\n",
    "print(classification_report(y_val_5, y_val_pred_1_to_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4cc66027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9853493699501259\n",
      "Mean Macro Precision across all folds: 0.9765541126349143\n",
      "Mean Macro Recall across all folds: 0.9825605244447931\n",
      "Mean Macro F1 Score across all folds: 0.9794844480620863\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the weight ratio \n",
    "weight_ratio = {0: 1, 1: 10}\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified weight ratio\n",
    "model_weighted = DecisionTreeClassifier(class_weight=weight_ratio)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31104ec6",
   "metadata": {},
   "source": [
    "## 3.2 Max Depth\n",
    "This parameter specifies the maximum depth of the decision tree. If set to None (default), nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7ca39932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 11}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [ 2, 3, 5, 7, 9, 11, 16, 20, None] \n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ac12d",
   "metadata": {},
   "source": [
    "### 3.2.1 Max Depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eb17cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Depth of 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      3608\n",
      "           1       0.80      0.91      0.85      1082\n",
      "\n",
      "    accuracy                           0.93      4690\n",
      "   macro avg       0.88      0.92      0.90      4690\n",
      "weighted avg       0.93      0.93      0.93      4690\n",
      "\n",
      "Validation set classification report with Max Depth of 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.95       767\n",
      "           1       0.14      0.79      0.24        14\n",
      "\n",
      "    accuracy                           0.91       781\n",
      "   macro avg       0.57      0.85      0.60       781\n",
      "weighted avg       0.98      0.91      0.94       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max depth\n",
    "max_depth = 3\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "model_max_depth_3 = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_depth_3.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_depth_3 = model_max_depth_3.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Depth of 3\")\n",
    "print(classification_report(y_train_5, model_max_depth_3.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Depth of 3:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_depth_3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "b499be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9101483252893109\n",
      "Mean Macro Precision across all folds: 0.8634389771931652\n",
      "Mean Macro Recall across all folds: 0.9033029265369045\n",
      "Mean Macro F1 Score across all folds: 0.8804853734849463\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the max depth\n",
    "max_depth = 3\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1cd48e",
   "metadata": {},
   "source": [
    "### 3.2.2 Max Depth = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4640d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Depth of 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3608\n",
      "           1       0.95      1.00      0.98      1082\n",
      "\n",
      "    accuracy                           0.99      4690\n",
      "   macro avg       0.98      0.99      0.98      4690\n",
      "weighted avg       0.99      0.99      0.99      4690\n",
      "\n",
      "Validation set classification report with Max Depth of 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.38      0.64      0.47        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.68      0.81      0.73       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max depth\n",
    "max_depth = 7\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_depth_7 = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_depth_7.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_depth_7 = model_max_depth_7.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Depth of 7\")\n",
    "print(classification_report(y_train_5, model_max_depth_7.predict(X_train_5)))\n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Depth of 7:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_depth_7)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f4bd436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9733890992595475\n",
      "Mean Macro Precision across all folds: 0.9541705952127243\n",
      "Mean Macro Recall across all folds: 0.9734343970456232\n",
      "Mean Macro F1 Score across all folds: 0.9633168140826008\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the max depth\n",
    "max_depth = 7\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131a23f",
   "metadata": {},
   "source": [
    "### 3.2.3 Max Depth = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a9fac2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Depth of 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Max Depth of 25:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max depth\n",
    "max_depth = 25\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "model_max_depth_25 = DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_depth_25.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_depth_25 = model_max_depth_25.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Depth of 25\")\n",
    "print(classification_report(y_train_5, model_max_depth_25.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Depth of 25:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_depth_25)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ede919a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the max depth\n",
    "max_depth = 25\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, max_depth=max_depth)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5eac4",
   "metadata": {},
   "source": [
    "## 3.3 Min Samples Split\n",
    "This parameter specifies the minimum number of samples required to split an internal node. If set to an integer, it ensures that a node is split only if it contains at least that number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "64fb0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_samples_split': [2, 5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9d4b",
   "metadata": {},
   "source": [
    "### 3.3.1 Min Samples Split = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "61f24808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Split of 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Min Samples Split of 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.40      0.43      0.41        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.71      0.70       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples split\n",
    "min_samples_split = 4\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "model_min_samples_split_4= DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_split_4.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_split_4 = model_min_samples_split_4.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Split of 4\")\n",
    "print(classification_report(y_train_5, model_min_samples_split_4.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Split of 4:\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_split_4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d6f3d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9816115547714637\n",
      "Mean Macro Precision across all folds: 0.9726273129211587\n",
      "Mean Macro Recall across all folds: 0.9757885295913523\n",
      "Mean Macro F1 Score across all folds: 0.9741791811572748\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples split\n",
    "min_samples_split = 4\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108fe21",
   "metadata": {},
   "source": [
    "### 3.3.2 Min Samples Split = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9536e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Split of 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      0.99      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Min Samples Split of 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples split\n",
    "min_samples_split = 10\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_samples_split_10= DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_split_10.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_split_10 = model_min_samples_split_10.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Split of 10\")\n",
    "print(classification_report(y_train_5, model_min_samples_split_10.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Split of 10:\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_split_10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "eb0d76c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9808638352154893\n",
      "Mean Macro Precision across all folds: 0.9718903958909355\n",
      "Mean Macro Recall across all folds: 0.974430301850633\n",
      "Mean Macro F1 Score across all folds: 0.9731312547058406\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples split\n",
    "min_samples_split = 10\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "model= DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa85d0",
   "metadata": {},
   "source": [
    "### 3.3.3 Min Samples Split = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8ea5b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Split of 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3608\n",
      "           1       0.95      0.99      0.97      1082\n",
      "\n",
      "    accuracy                           0.99      4690\n",
      "   macro avg       0.97      0.99      0.98      4690\n",
      "weighted avg       0.99      0.99      0.99      4690\n",
      "\n",
      "Validation set classification report with Min Samples Split of 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.33      0.57      0.42        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.66      0.78      0.70       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples split\n",
    "min_samples_split = 50\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_samples_split_50= DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_split_50.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_split_50 = model_min_samples_split_50.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Split of 50\")\n",
    "print(classification_report(y_train_5, model_min_samples_split_50.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Split of 50:\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_split_50)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "896079ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9709974699620887\n",
      "Mean Macro Precision across all folds: 0.960229882015688\n",
      "Mean Macro Recall across all folds: 0.9580522497803908\n",
      "Mean Macro F1 Score across all folds: 0.9590846952696456\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples split\n",
    "min_samples_split = 50\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38324de3",
   "metadata": {},
   "source": [
    "## 3.4 CCP Alpha\n",
    "This is the complexity parameter used for Minimal Cost-Complexity Pruning (CCP). It specifies the non-negative cost complexity parameter of the Decision Tree. Increasing ccp_alpha increases the pruning strength, potentially resulting in a simpler tree that generalizes better to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5be770ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ccp_alpha': 0.0}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'ccp_alpha': [0.0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe4ad1",
   "metadata": {},
   "source": [
    "### 3.4.1 CCP Alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "3e2c906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with CCP Alpha of 0.0001:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with CCP Alpha of 0.001:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.0001\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_ccp_alpha_0001= DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_ccp_alpha_0001.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_ccp_alpha_0001 = model_ccp_alpha_0001.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with CCP Alpha of 0.0001:\")\n",
    "print(classification_report(y_train_5, model_ccp_alpha_0001.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with CCP Alpha of 0.001:\")\n",
    "print(classification_report(y_val_5, y_val_pred_ccp_alpha_0001)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "432a7105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9816115547714637\n",
      "Mean Macro Precision across all folds: 0.9726273129211587\n",
      "Mean Macro Recall across all folds: 0.9757885295913523\n",
      "Mean Macro F1 Score across all folds: 0.9741791811572748\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.0001\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd9b96",
   "metadata": {},
   "source": [
    "### 3.4.2 CCP Alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f7300aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with CCP Alpha of 0.01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3608\n",
      "           1       0.89      0.91      0.90      1082\n",
      "\n",
      "    accuracy                           0.95      4690\n",
      "   macro avg       0.93      0.94      0.93      4690\n",
      "weighted avg       0.95      0.95      0.95      4690\n",
      "\n",
      "Validation set classification report with CCP Alpha of 0.01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.26      0.64      0.37        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.80      0.67       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_ccp_alpha_01= DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_ccp_alpha_01.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_ccp_alpha_01 = model_ccp_alpha_01.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with CCP Alpha of 0.01:\")\n",
    "print(classification_report(y_train_5, model_ccp_alpha_01.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with CCP Alpha of 0.01:\")\n",
    "print(classification_report(y_val_5, y_val_pred_ccp_alpha_01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c943f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9709974699620887\n",
      "Mean Macro Precision across all folds: 0.960229882015688\n",
      "Mean Macro Recall across all folds: 0.9580522497803908\n",
      "Mean Macro F1 Score across all folds: 0.9590846952696456\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efb694",
   "metadata": {},
   "source": [
    "### 3.4.3 CCP Alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0e5a8621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with CCP Alpha of 0.05:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      3608\n",
      "           1       0.74      0.91      0.81      1082\n",
      "\n",
      "    accuracy                           0.90      4690\n",
      "   macro avg       0.85      0.90      0.87      4690\n",
      "weighted avg       0.92      0.90      0.91      4690\n",
      "\n",
      "Validation set classification report with CCP Alpha of 0.05:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       767\n",
      "           1       0.12      0.79      0.20        14\n",
      "\n",
      "    accuracy                           0.89       781\n",
      "   macro avg       0.56      0.84      0.57       781\n",
      "weighted avg       0.98      0.89      0.93       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.05\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_ccp_alpha_05= DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_ccp_alpha_05.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_ccp_alpha_05 = model_ccp_alpha_05.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with CCP Alpha of 0.05:\")\n",
    "print(classification_report(y_train_5, model_ccp_alpha_05.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with CCP Alpha of 0.05:\")\n",
    "print(classification_report(y_val_5, y_val_pred_ccp_alpha_05)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dfe04dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9709974699620887\n",
      "Mean Macro Precision across all folds: 0.960229882015688\n",
      "Mean Macro Recall across all folds: 0.9580522497803908\n",
      "Mean Macro F1 Score across all folds: 0.9590846952696456\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the CCP Alpha\n",
    "ccp_alpha = 0.05\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_split=min_samples_split)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f99154",
   "metadata": {},
   "source": [
    "## 3.5 Criterion\n",
    "This specifies the function to measure the quality of a split. It can take two values: 'gini' for the Gini impurity and 'entropy' for the information gain. These criteria determine how the decision tree selects the best feature to split on at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "15b305a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcbe89",
   "metadata": {},
   "source": [
    "### 3.5.1 Criterion = Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "89303145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Criterion Gini:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Criterion Gini:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the citerion\n",
    "criterion = 'gini'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_criterion_gini= DecisionTreeClassifier(random_state=42, criterion=criterion)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_criterion_gini.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_criterion_gini = model_criterion_gini.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Criterion Gini:\")\n",
    "print(classification_report(y_train_5, model_criterion_gini.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Criterion Gini:\")\n",
    "print(classification_report(y_val_5, y_val_pred_criterion_gini)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "cf69d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "criterion = 'gini'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, criterion=criterion)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbedbc7",
   "metadata": {},
   "source": [
    "### 3.5.2 Criterion = Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b43e431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Criterion Entropy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Criterion Entropy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.56      0.64      0.60        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.78      0.82      0.80       781\n",
      "weighted avg       0.99      0.98      0.99       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the citerion\n",
    "criterion = 'entropy'\n",
    "\n",
    "# Initialize Decision Tree Classifier with the specified \n",
    "model_criterion_entropy= DecisionTreeClassifier(random_state=42, criterion=criterion)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_criterion_entropy.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_criterion_entropy = model_criterion_entropy.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Criterion Entropy:\")\n",
    "print(classification_report(y_train_5, model_criterion_entropy.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Criterion Entropy:\")\n",
    "print(classification_report(y_val_5, y_val_pred_criterion_entropy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ab157e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9859470536741449\n",
      "Mean Macro Precision across all folds: 0.9770516720066331\n",
      "Mean Macro Recall across all folds: 0.9838546336852257\n",
      "Mean Macro F1 Score across all folds: 0.9803561909244823\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "criterion = 'entropy'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, criterion=criterion)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726e2e1",
   "metadata": {},
   "source": [
    "## 3.6 Max_features: \n",
    "\n",
    "This parameter specifies the number of features to consider when looking for the best split. It can take various values like 'auto', 'sqrt', 'log2', or an integer. If set to None (default), all features will be considered for splitting at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d155d7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eddc0b",
   "metadata": {},
   "source": [
    "### 3.6.1 Max Features = auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "03fd6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Features Auto:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Max Features Auto:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrietsmacbook/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the max features\n",
    "max_features = 'auto'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_features_auto= DecisionTreeClassifier(random_state=42, max_features=max_features)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_features_auto.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_features_auto = model_max_features_auto.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Features Auto:\")\n",
    "print(classification_report(y_train_5, model_max_features_auto.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Features Auto:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_features_auto)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c07f8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9822094620958284\n",
      "Mean Macro Precision across all folds: 0.9720731100854678\n",
      "Mean Macro Recall across all folds: 0.9782404882256246\n",
      "Mean Macro F1 Score across all folds: 0.9751059651397431\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "max_features = 'sqrt'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, max_features=max_features)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa914ed8",
   "metadata": {},
   "source": [
    "### 3.6.2 Max Features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6f4984c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Features None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Max Features None:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max features\n",
    "max_features = None\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_features_none= DecisionTreeClassifier(random_state=42, max_features=max_features)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_features_none.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_features_none = model_max_features_none.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Features None:\")\n",
    "print(classification_report(y_train_5, model_max_features_none.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Features None:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_features_none)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "116ec25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "max_features = None\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, max_features=max_features)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf40422",
   "metadata": {},
   "source": [
    "## 3.7 Max Leaf Nodes\n",
    "This parameter specifies the maximum number of leaf nodes in the decision tree. If set, the tree will be pruned such that it has no more than this number of leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9cedb2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_leaf_nodes': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_leaf_nodes': [None, 10, 50, 100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73311be",
   "metadata": {},
   "source": [
    "### 3.7.1 Max Leaf Nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8d89c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Leaf Nodes 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3608\n",
      "           1       0.91      0.95      0.93      1082\n",
      "\n",
      "    accuracy                           0.97      4690\n",
      "   macro avg       0.95      0.96      0.95      4690\n",
      "weighted avg       0.97      0.97      0.97      4690\n",
      "\n",
      "Validation set classification report with Max Leaf Nodes 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       767\n",
      "           1       0.26      0.71      0.38        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.84      0.68       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max leaf nodes\n",
    "max_leaf_nodes = 10\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_leaf_nodes_10= DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_leaf_nodes_10.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_leaf_nodes_10 = model_max_leaf_nodes_10.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Leaf Nodes 10:\")\n",
    "print(classification_report(y_train_5, model_max_leaf_nodes_10.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Leaf Nodes 10:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_leaf_nodes_10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "72ed5085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9544011815042266\n",
      "Mean Macro Precision across all folds: 0.9237114034737788\n",
      "Mean Macro Recall across all folds: 0.9560571268872972\n",
      "Mean Macro F1 Score across all folds: 0.9383293765871397\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "max_leaf_nodes = 10\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb47227",
   "metadata": {},
   "source": [
    "### 3.7.2 Max Leaf Nodes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "eb422f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Leaf Nodes 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       0.99      1.00      0.99      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       0.99      1.00      0.99      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Max Leaf Nodes 50:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.57      0.50        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.72      0.78      0.74       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max leaf nodes\n",
    "max_leaf_nodes = 50\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_leaf_nodes_50= DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_leaf_nodes_50.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_leaf_nodes_50 = model_max_leaf_nodes_50.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Leaf Nodes 50:\")\n",
    "print(classification_report(y_train_5, model_max_leaf_nodes_50.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Leaf Nodes 50:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_leaf_nodes_50)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "180e3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9787708241796942\n",
      "Mean Macro Precision across all folds: 0.9667054202586115\n",
      "Mean Macro Recall across all folds: 0.9741919740247201\n",
      "Mean Macro F1 Score across all folds: 0.9703493371252119\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "max_leaf_nodes = 50\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6616e30",
   "metadata": {},
   "source": [
    "### 3.7.3 Max Leaf Nodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3b1b165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Max Leaf Nodes 100:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Max Leaf Nodes 100:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.47      0.50      0.48        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.73      0.74      0.74       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the max leaf nodes\n",
    "max_leaf_nodes = 100\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_max_leaf_nodes_100= DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_max_leaf_nodes_100.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_max_leaf_nodes_100 = model_max_leaf_nodes_100.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Max Leaf Nodes 100:\")\n",
    "print(classification_report(y_train_5, model_max_leaf_nodes_100.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Max Leaf Nodes 100:\")\n",
    "print(classification_report(y_val_5, y_val_pred_max_leaf_nodes_100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "4f81acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9844520617628876\n",
      "Mean Macro Precision across all folds: 0.9765023793186683\n",
      "Mean Macro Recall across all folds: 0.9799211671969289\n",
      "Mean Macro F1 Score across all folds: 0.9781788055034651\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "max_leaf_nodes = 100\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe096a",
   "metadata": {},
   "source": [
    "## 3.8 Min impurity decrease\n",
    "This parameter specifies a threshold for early stopping of tree growth. A split will only be considered if it induces a decrease of the impurity greater than or equal to this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ac797640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_impurity_decrease': 0.0}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13cf7cd",
   "metadata": {},
   "source": [
    "### 3.8.1 Min impurity decrease = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "72695628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min impurity decrease 0.0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Min impurity decrease 0.0:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min impurity decrease\n",
    "min_impurity_decrease = 0.0\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_impurity_decrease_0= DecisionTreeClassifier(random_state=42,min_impurity_decrease=min_impurity_decrease )\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_impurity_decrease_0.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_impurity_decrease_0 = model_min_impurity_decrease_0.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min impurity decrease 0.0:\")\n",
    "print(classification_report(y_train_5, model_min_impurity_decrease_0.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min impurity decrease 0.0:\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_impurity_decrease_0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "62b22abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "min_impurity_decrease = 0.0\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_impurity_decrease=min_impurity_decrease)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe909f3",
   "metadata": {},
   "source": [
    "### 3.8.2 Min impurity decrease = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5c121f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min impurity decrease 0.01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3608\n",
      "           1       0.89      0.91      0.90      1082\n",
      "\n",
      "    accuracy                           0.95      4690\n",
      "   macro avg       0.93      0.94      0.93      4690\n",
      "weighted avg       0.95      0.95      0.95      4690\n",
      "\n",
      "Validation set classification report with Min impurity decrease 0.01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.26      0.64      0.37        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.80      0.67       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min impurity decrease\n",
    "min_impurity_decrease = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_impurity_decrease_01= DecisionTreeClassifier(random_state=42, min_impurity_decrease=min_impurity_decrease)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_impurity_decrease_01.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_impurity_decrease_01 = model_min_impurity_decrease_01.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min impurity decrease 0.01:\")\n",
    "print(classification_report(y_train_5, model_min_impurity_decrease_01.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min impurity decrease 0.01:\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_impurity_decrease_01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "38415ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.95156056271263\n",
      "Mean Macro Precision across all folds: 0.9183514998164422\n",
      "Mean Macro Recall across all folds: 0.9555872269936243\n",
      "Mean Macro F1 Score across all folds: 0.9348968031534944\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the criterion\n",
    "min_impurity_decrease = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_impurity_decrease=min_impurity_decrease)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031c7c8",
   "metadata": {},
   "source": [
    "## 3.9 Min Samples Leaf\n",
    "This parameter specifies the minimum number of samples required to be at a leaf node. If set to an integer, it ensures that each leaf node has at least that number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6ac9cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 10, 15, 20, 25, 30]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2626b6cc",
   "metadata": {},
   "source": [
    "### 3.9.1 Min Samples Leaf = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "45cd5444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Leaf of 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      0.98      0.99      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      0.99      0.99      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Min Samples Leaf of 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples leaf\n",
    "min_samples_leaf = 2\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_samples_leaf_2= DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_leaf_2.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_leaf_2 = model_min_samples_leaf_2.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Leaf of 2\")\n",
    "print(classification_report(y_train_5, model_min_samples_leaf_2.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Leaf of 2\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_leaf_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d0a359b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9783223936864207\n",
      "Mean Macro Precision across all folds: 0.9696147059479218\n",
      "Mean Macro Recall across all folds: 0.9693905744670716\n",
      "Mean Macro F1 Score across all folds: 0.96946408096941\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples leaf\n",
    "min_samples_leaf=2\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ea028",
   "metadata": {},
   "source": [
    "### 3.9.2 Min Samples Leaf = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8a2f9c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Leaf of 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3608\n",
      "           1       0.98      0.98      0.98      1082\n",
      "\n",
      "    accuracy                           0.99      4690\n",
      "   macro avg       0.99      0.99      0.99      4690\n",
      "weighted avg       0.99      0.99      0.99      4690\n",
      "\n",
      "Validation set classification report with Min Samples Leaf of 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.40      0.57      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.78      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples leaf\n",
    "min_samples_leaf = 5\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_samples_leaf_5= DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_leaf_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_leaf_5 = model_min_samples_leaf_5.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Leaf of 5\")\n",
    "print(classification_report(y_train_5, model_min_samples_leaf_5.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Leaf of 5\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_leaf_5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "57a145d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9783225054865934\n",
      "Mean Macro Precision across all folds: 0.9691725210592539\n",
      "Mean Macro Recall across all folds: 0.9698051543560158\n",
      "Mean Macro F1 Score across all folds: 0.9694654644806568\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples leaf\n",
    "min_samples_leaf=5\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa88f45",
   "metadata": {},
   "source": [
    "### 3.9.3 Min Samples Leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "00041c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Samples Leaf of 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3608\n",
      "           1       0.97      0.99      0.98      1082\n",
      "\n",
      "    accuracy                           0.99      4690\n",
      "   macro avg       0.98      0.99      0.99      4690\n",
      "weighted avg       0.99      0.99      0.99      4690\n",
      "\n",
      "Validation set classification report with Min Samples Leaf of 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       767\n",
      "           1       0.42      0.79      0.55        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.88      0.77       781\n",
      "weighted avg       0.99      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples leaf\n",
    "min_samples_leaf = 10\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_samples_leaf_10= DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_samples_leaf_10.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_samples_leaf_10 = model_min_samples_leaf_10.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Samples Leaf of 10\")\n",
    "print(classification_report(y_train_5, model_min_samples_leaf_10.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Samples Leaf of 10\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_samples_leaf_10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "9b909ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9733889874593746\n",
      "Mean Macro Precision across all folds: 0.9627198910162218\n",
      "Mean Macro Recall across all folds: 0.9623061576783994\n",
      "Mean Macro F1 Score across all folds: 0.9624889591091517\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples leaf\n",
    "min_samples_leaf=10\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43432f",
   "metadata": {},
   "source": [
    "## 3.10 Min Weight Fraction Leaf\n",
    "This parameter specifies the minimum weighted fraction of the total number of samples required to be at a leaf node. It works similarly to min_samples_leaf, but the samples are weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fea80205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_weight_fraction_leaf': 0.0}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'min_weight_fraction_leaf': [0.0, 0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108fb0f8",
   "metadata": {},
   "source": [
    "### 3.10.1 Min Weight Fraction Leaf = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dbe13df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Weight Fraction Leaf of 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      3608\n",
      "           1       0.90      0.93      0.92      1082\n",
      "\n",
      "    accuracy                           0.96      4690\n",
      "   macro avg       0.94      0.95      0.95      4690\n",
      "weighted avg       0.96      0.96      0.96      4690\n",
      "\n",
      "Validation set classification report with Min Weight Fraction Leaf of 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       767\n",
      "           1       0.26      0.71      0.38        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.84      0.68       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples leaf\n",
    "min_weight_fraction_leaf = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_weight_fraction_leaf_01= DecisionTreeClassifier(random_state=42, min_weight_fraction_leaf=min_weight_fraction_leaf)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_weight_fraction_leaf_01.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_weight_fraction_leaf_01 = model_min_weight_fraction_leaf_01.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Weight Fraction Leaf of 0.01\")\n",
    "print(classification_report(y_train_5, model_min_weight_fraction_leaf_01.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Weight Fraction Leaf of 0.01\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_weight_fraction_leaf_01)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "ee6c6cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9500655708013725\n",
      "Mean Macro Precision across all folds: 0.923858726472473\n",
      "Mean Macro Recall across all folds: 0.9401168210853887\n",
      "Mean Macro F1 Score across all folds: 0.931220782707163\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples leaf\n",
    "min_weight_fraction_leaf = 0.01\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, min_weight_fraction_leaf=min_weight_fraction_leaf)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467c23f",
   "metadata": {},
   "source": [
    "### 3.10.2 Min Weight Fraction Leaf = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6a1b3964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Min Weight Fraction Leaf of 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      3608\n",
      "           1       0.74      0.91      0.81      1082\n",
      "\n",
      "    accuracy                           0.90      4690\n",
      "   macro avg       0.85      0.90      0.87      4690\n",
      "weighted avg       0.92      0.90      0.91      4690\n",
      "\n",
      "Validation set classification report with Min Weight Fraction Leaf of 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       767\n",
      "           1       0.12      0.79      0.20        14\n",
      "\n",
      "    accuracy                           0.89       781\n",
      "   macro avg       0.56      0.84      0.57       781\n",
      "weighted avg       0.98      0.89      0.93       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the min samples leaf\n",
    "min_weight_fraction_leaf = 0.1\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_min_weight_fraction_leaf_1= DecisionTreeClassifier(random_state=42, min_weight_fraction_leaf=min_weight_fraction_leaf)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_min_weight_fraction_leaf_1.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_min_weight_fraction_leaf_1 = model_min_weight_fraction_leaf_1.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Min Weight Fraction Leaf of 0.1\")\n",
    "print(classification_report(y_train_5, model_min_weight_fraction_leaf_1.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Min Weight Fraction Leaf of 0.1\")\n",
    "print(classification_report(y_val_5, y_val_pred_min_weight_fraction_leaf_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "47dad567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.8886213138085512\n",
      "Mean Macro Precision across all folds: 0.8346131810652592\n",
      "Mean Macro Recall across all folds: 0.8899970911213071\n",
      "Mean Macro F1 Score across all folds: 0.8559323111336876\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the min samples leaf\n",
    "min_weight_fraction_leaf = 0.1\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, min_weight_fraction_leaf=min_weight_fraction_leaf)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28520342",
   "metadata": {},
   "source": [
    "## 3.11 Splitter\n",
    "This parameter specifies the strategy used to choose the split at each node. It can take two values: 'best' to choose the best split based on the selected criterion, or 'random' to choose the best random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b123b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcbdb1",
   "metadata": {},
   "source": [
    "### 3.11.1 Splitter = Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0acc91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Splitter Best\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Splitter Best\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the splitter\n",
    "splitter= 'best'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_splitter_best= DecisionTreeClassifier(random_state=42, splitter=splitter)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_splitter_best.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_splitter_best = model_splitter_best.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Splitter Best\")\n",
    "print(classification_report(y_train_5, model_splitter_best.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Splitter Best\")\n",
    "print(classification_report(y_val_5, y_val_pred_splitter_best)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "5dc94934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.9832560235138124\n",
      "Mean Macro Precision across all folds: 0.9744511141707222\n",
      "Mean Macro Recall across all folds: 0.9786795899451987\n",
      "Mean Macro F1 Score across all folds: 0.9765242241110277\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the splitter\n",
    "splitter = 'best'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model = DecisionTreeClassifier(random_state=42, splitter=splitter)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d2d0a",
   "metadata": {},
   "source": [
    "### 3.11.2 Splitter = Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "22c2d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with Splitter Random\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with Splitter Random\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.40      0.57      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.78      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the splitter\n",
    "splitter= 'random'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_splitter_random= DecisionTreeClassifier(random_state=42, splitter=splitter)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_splitter_random.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_splitter_random = model_splitter_random.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with Splitter Random\")\n",
    "print(classification_report(y_train_5, model_splitter_random.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with Splitter Random\")\n",
    "print(classification_report(y_val_5, y_val_pred_splitter_random)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "86d9d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.981611442971291\n",
      "Mean Macro Precision across all folds: 0.9693907017878496\n",
      "Mean Macro Recall across all folds: 0.9796694516088633\n",
      "Mean Macro F1 Score across all folds: 0.974389887254939\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the splitter\n",
    "splitter = 'random'\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, splitter=splitter)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3fd6e",
   "metadata": {},
   "source": [
    "# 4. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcdd10",
   "metadata": {},
   "source": [
    "## 4.1 Best Model based on individual performance\n",
    "\n",
    "When individually tuning the individual parameters of the decision tree model, the following parameters produced the best performance:\n",
    "- class_weight={0: 1, 1: 10}\n",
    "- max_depth=25\n",
    "- min_samples_split=50\n",
    "- ccp_alpha=0.005\n",
    "- max_leaf_nodes=10\n",
    "- min_impurity_decrease=0.01\n",
    "- min_samples_leaf=10\n",
    "-  min_weight_fraction_leaf=0.1\n",
    "- criterion='entropy'\n",
    "- max_features=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "92a5942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      3608\n",
      "           1       0.62      0.96      0.76      1082\n",
      "\n",
      "    accuracy                           0.86      4690\n",
      "   macro avg       0.80      0.89      0.83      4690\n",
      "weighted avg       0.90      0.86      0.87      4690\n",
      "\n",
      "Validation set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91       767\n",
      "           1       0.07      0.64      0.12        14\n",
      "\n",
      "    accuracy                           0.83       781\n",
      "   macro avg       0.53      0.74      0.51       781\n",
      "weighted avg       0.98      0.83      0.89       781\n",
      "\n",
      "Test set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89       770\n",
      "           1       0.06      0.75      0.10        12\n",
      "\n",
      "    accuracy                           0.80       782\n",
      "   macro avg       0.53      0.78      0.50       782\n",
      "weighted avg       0.98      0.80      0.88       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree Classifier \n",
    "model_best_features = DecisionTreeClassifier(random_state=42, \n",
    "                                             class_weight={0: 1, 1: 10},\n",
    "                                             max_depth=25,\n",
    "                                             min_samples_split=50,\n",
    "                                             ccp_alpha=0.005,\n",
    "                                             max_leaf_nodes=10,\n",
    "                                             min_impurity_decrease=0.01,\n",
    "                                             min_samples_leaf=10,\n",
    "                                             min_weight_fraction_leaf=0.1,\n",
    "                                             criterion='entropy',\n",
    "                                             max_features=None)\n",
    "\n",
    "                                            \n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_best_features.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_best_features = model_best_features.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with best features:\")\n",
    "print(classification_report(y_train_5, model_best_features.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with best features:\")\n",
    "print(classification_report(y_val_5, y_val_pred_best_features)) \n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred_best_features = model_best_features.predict(X_test_5)\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test set classification report with best features:\")\n",
    "print(classification_report(y_test_5, y_test_pred_best_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "4ae52b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds: 0.824935016149535\n",
      "Mean Macro Precision across all folds: 0.7706298402562786\n",
      "Mean Macro Recall across all folds: 0.8500641434229197\n",
      "Mean Macro F1 Score across all folds: 0.7893955387366047\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model= DecisionTreeClassifier(random_state=42, \n",
    "                                             class_weight={0: 1, 1: 10},\n",
    "                                             max_depth=25,\n",
    "                                             min_samples_split=50,\n",
    "                                             ccp_alpha=0.005,\n",
    "                                             max_leaf_nodes=10,\n",
    "                                             min_impurity_decrease=0.01,\n",
    "                                             min_samples_leaf=10,\n",
    "                                             min_weight_fraction_leaf=0.1,\n",
    "                                             criterion='entropy',\n",
    "                                             max_features=None)\n",
    "\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies= []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf4280",
   "metadata": {},
   "source": [
    "## 4.3 Best Model based on Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7db1df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'ccp_alpha': 0.0, 'class_weight': {0: 1, 1: 10}, 'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 2}, {0: 1, 1: 5}, {0: 1, 1: 10}],\n",
    "    'max_depth': [ 2, 3, 5, 11, None],\n",
    "    'min_samples_split': [2, 5, 50],\n",
    "    'ccp_alpha': [0.0, 0.001,0.05],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "                  #'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "                  'max_leaf_nodes': [None, 10, 50, 100],\n",
    "                  'min_impurity_decrease': [0.0, 0.01],\n",
    "                  'min_samples_leaf': [1, 2, 5, 10],\n",
    "                  'min_weight_fraction_leaf': [0.0, 0.01, 0.05],\n",
    "                  'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_five_features, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c99bf3",
   "metadata": {},
   "source": [
    "**Grid Search Results:**\n",
    "\n",
    "- class_weight={0: 1, 1: 10}\n",
    "- max_depth=None \n",
    "- max_leaf_nodes=50 \n",
    "- min_impurity_decrease=0\n",
    "- min_samples_leaf=1\n",
    "- min_samples_split=5\n",
    "- min_weight_fraction_leaf=0\n",
    "- splitter='best'\n",
    "- ccp_alpha=0.0\n",
    "- criterion='entropy'\n",
    "- max_features=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "25033ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with best grid search results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       0.99      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with best grid search results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Test set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       770\n",
      "           1       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.98       782\n",
      "   macro avg       0.73      0.79      0.76       782\n",
      "weighted avg       0.99      0.98      0.98       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Decision Tree Classifier \n",
    "model_best_grid = DecisionTreeClassifier(random_state=42, \n",
    "                                         class_weight={0: 1, 1: 10}, \n",
    "                                         max_depth=None, \n",
    "                                         max_leaf_nodes=50, \n",
    "                                         min_impurity_decrease=0,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         min_samples_split=5,\n",
    "                                         min_weight_fraction_leaf=0,\n",
    "                                         splitter='best',\n",
    "                                         ccp_alpha=0.0, \n",
    "                                         criterion='entropy', \n",
    "                                         max_features=None)\n",
    "\n",
    "# Fit the model on the full training data\n",
    "model_best_grid.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_best_grid = model_best_grid.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with best grid search results:\")\n",
    "print(classification_report(y_train_5, model_best_grid.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with best grid search results:\")\n",
    "print(classification_report(y_val_5, y_val_pred_best_grid))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred_best_grid = model_best_grid.predict(X_test_5)\n",
    "\n",
    "# Print classification report for test set\n",
    "print(\"Test set classification report with best features:\")\n",
    "print(classification_report(y_test_5, y_test_pred_best_grid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "233ba1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Macro Accuracy across all folds (weighted): 0.9860963069048905\n",
      "Mean Macro Precision across all folds (weighted): 0.9797420809172899\n",
      "Mean Macro Recall across all folds (weighted): 0.9812722829223588\n",
      "Mean Macro F1 Score across all folds (weighted): 0.9804665984613699\n"
     ]
    }
   ],
   "source": [
    "X_full = df_full[['distance', 'orbital_radius', 'mass_earth', 'radius_earth', 'stellar_magnitude']]\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize Decision Tree Classifier \n",
    "model_grid_search = DecisionTreeClassifier(random_state=42, \n",
    "                                         class_weight={0: 1, 1: 10}, \n",
    "                                         max_depth=None, \n",
    "                                         max_leaf_nodes=50, \n",
    "                                         min_impurity_decrease=0,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         min_samples_split=5,\n",
    "                                         min_weight_fraction_leaf=0,\n",
    "                                         splitter='best',\n",
    "                                         ccp_alpha=0.0, \n",
    "                                         criterion='entropy', \n",
    "                                         max_features=None)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies_weighted = []\n",
    "fold_precisions_weighted = []\n",
    "fold_recalls_weighted = []\n",
    "fold_f1_scores_weighted = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model_weighted.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = model_weighted.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies_weighted.append(accuracy)\n",
    "    fold_precisions_weighted.append(precision)\n",
    "    fold_recalls_weighted.append(recall)\n",
    "    fold_f1_scores_weighted.append(f1)\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy_weighted = sum(fold_accuracies_weighted) / len(fold_accuracies_weighted)\n",
    "mean_precision_weighted = sum(fold_precisions_weighted) / len(fold_precisions_weighted)\n",
    "mean_recall_weighted = sum(fold_recalls_weighted) / len(fold_recalls_weighted)\n",
    "mean_f1_weighted = sum(fold_f1_scores_weighted) / len(fold_f1_scores_weighted)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds (weighted): {mean_accuracy_weighted}')\n",
    "print(f'Mean Macro Precision across all folds (weighted): {mean_precision_weighted}')\n",
    "print(f'Mean Macro Recall across all folds (weighted): {mean_recall_weighted}')\n",
    "print(f'Mean Macro F1 Score across all folds (weighted): {mean_f1_weighted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6da8c1",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d599d",
   "metadata": {},
   "source": [
    "## 5.1 Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "6b66a5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[618 152]\n",
      " [  3   9]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y_pred = model_best_features.predict(X_test_5)\n",
    "# Print confusion matrix for best model\n",
    "cm = confusion_matrix(y_test_5, y_pred)\n",
    "print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Plot confusion matrix with values in the boxes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Not Habitable', 'Habitable'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Not Habitable', 'Habitable'])\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac145276",
   "metadata": {},
   "source": [
    "## 5.2 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "a6135144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[762   8]\n",
      " [  5   7]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model_best_grid.predict(X_test_5)\n",
    "# Print confusion matrix for best model\n",
    "cm = confusion_matrix(y_test_5, y_pred)\n",
    "print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Plot confusion matrix with values in the boxes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Not Habitable', 'Habitable'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Not Habitable', 'Habitable'])\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e419e76",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Overall, the model based on Grid Search performs significantly better than the model that has been tuned based on the individually best performing parameters. Overall a macro average F1 score of 76% is reached in the test data with this resulting model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6064f",
   "metadata": {},
   "source": [
    "# 6. Run time Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "41effa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree training time: 0.10 seconds\n",
      "Decision Tree prediction time: 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize a dictionary to store training and prediction times\n",
    "training_times = {}\n",
    "\n",
    "# Start measuring time for training\n",
    "start_time = time.time()\n",
    "model_best_grid.fit(X_train_5, y_train_5)  # Train the model\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training duration\n",
    "training_duration = end_time - start_time\n",
    "\n",
    "# Start measuring time for prediction\n",
    "start_time = time.time()\n",
    "predictions = model_best_grid.predict(X_test_5)\n",
    "prediction_time = time.time() - start_time\n",
    "\n",
    "# Store times in the dictionary\n",
    "training_times['Decision Tree'] = {'Training Time': training_duration, 'Prediction Time': prediction_time}\n",
    "\n",
    "# Print the times\n",
    "print(f\"Decision Tree training time: {training_duration:.2f} seconds\")\n",
    "print(f\"Decision Tree prediction time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ac713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
