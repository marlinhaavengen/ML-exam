{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the datasets, which we have already split into training, testing, and validation \n",
    "df_full = pd.read_csv('Habitable_Full_Balanced.csv')\n",
    "df_train = pd.read_csv('Habitable_Train_Balanced.csv')\n",
    "df_test = pd.read_csv('Habitable_Test.csv')\n",
    "df_val = pd.read_csv('Habitable_Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5145\n",
      "1    1544\n",
      "Name: Habitable, dtype: int64\n",
      "0    3608\n",
      "1    1082\n",
      "Name: Habitable, dtype: int64\n",
      "0    770\n",
      "1     12\n",
      "Name: Habitable, dtype: int64\n",
      "0    767\n",
      "1     14\n",
      "Name: Habitable, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_full['Habitable'].value_counts())\n",
    "print(df_train['Habitable'].value_counts())\n",
    "print(df_test['Habitable'].value_counts())\n",
    "print(df_val['Habitable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 All features\n",
    "**Evaluating the default model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (4690, 6)\n",
      "Validation set size: (781, 6)\n",
      "Testing set size: (782, 6)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train = df_train.drop(columns=['Habitable'])\n",
    "y_train = df_train['Habitable']\n",
    "\n",
    "X_test = df_test.drop(columns=['Habitable'])\n",
    "y_test = df_test['Habitable']\n",
    "\n",
    "X_val = df_val.drop(columns=['Habitable'])\n",
    "y_val = df_val['Habitable']\n",
    "\n",
    "# Print the sizes of the resulting datasets\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "rf_all = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for training set\n",
    "y_train_pred = rf_all.predict(X_train)\n",
    "print(\"Training set classification report:\")\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.64      0.50      0.56        14\n",
      "\n",
      "    accuracy                           0.99       781\n",
      "   macro avg       0.81      0.75      0.78       781\n",
      "weighted avg       0.98      0.99      0.99       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report for validation set\n",
    "y_val_pred = rf_all.predict(X_val)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.992526158445441\n",
      "Precision: 0.9873886594347134\n",
      "Recall: 0.9917566210618802\n",
      "F1 Score: 0.9895505323136902\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021    7]\n",
      " [   3  307]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9887892376681614\n",
      "Precision: 0.9783875622585301\n",
      "Recall: 0.9904242593912247\n",
      "F1 Score: 0.9842375968264714\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021   13]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9955156950672646\n",
      "Precision: 0.9936735594502585\n",
      "Recall: 0.9936735594502585\n",
      "F1 Score: 0.9936735594502585\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1027    3]\n",
      " [   3  305]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9940209267563528\n",
      "Precision: 0.9882232960963977\n",
      "Recall: 0.9949703501985137\n",
      "F1 Score: 0.9915454778100387\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1027    7]\n",
      " [   1  303]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9887808526551982\n",
      "Precision: 0.9783549458535794\n",
      "Recall: 0.9915581930737374\n",
      "F1 Score: 0.9847400559264966\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1005   14]\n",
      " [   1  317]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9919265741184837\n",
      "Mean Macro Precision across all folds: 0.9852056046186959\n",
      "Mean Macro Recall across all folds: 0.9924765966351229\n",
      "Mean Macro F1 Score across all folds: 0.988749444465391\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "X_full = df_full.drop(columns=['Habitable'])\n",
    "y_full = df_full['Habitable']\n",
    "\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full), 1):\n",
    "    X_train = X_full.iloc[train_index]\n",
    "    y_train = y_full[train_index]\n",
    "    X_test = X_full.iloc[test_index]\n",
    "    y_test = y_full[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation take in a dataset where it has been applied SMOTE and is therefore more balanced. That leads to better results than the classification report for validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate feature importance for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance for the model\n",
    "importances = rf_all.feature_importances_\n",
    "features = X_train.columns\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             feature  importance\n",
      "0           distance    0.259445\n",
      "5       radius_earth    0.194661\n",
      "2     orbital_radius    0.188641\n",
      "3       eccentricity    0.135399\n",
      "4         mass_earth    0.112505\n",
      "1  stellar_magnitude    0.109350\n"
     ]
    }
   ],
   "source": [
    "# Feature importance scores\n",
    "feature_importances = rf_all.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({'feature': X_full.columns, 'importance': feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values('importance', ascending=False)\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_5 = df_train[['distance', 'radius_earth', 'orbital_radius', 'eccentricity', 'mass_earth']]\n",
    "y_train_5 = df_train['Habitable']\n",
    "\n",
    "X_test_5 = df_test[['distance', 'radius_earth', 'orbital_radius', 'eccentricity', 'mass_earth']]\n",
    "y_test_5 = df_test['Habitable']\n",
    "\n",
    "X_val_5 = df_val[['distance', 'radius_earth', 'orbital_radius', 'eccentricity', 'mass_earth']]\n",
    "y_val_5 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with fewer features\n",
    "rf_5 = model.fit(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for train set\n",
    "y_train_pred_5 = rf_5.predict(X_train_5)\n",
    "print(classification_report(y_train_5, y_train_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.37      0.50      0.42        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for validation set\n",
    "y_val_pred_5 = rf_5.predict(X_val_5)\n",
    "print(classification_report(y_val_5, y_val_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9880418535127056\n",
      "Precision: 0.9811467456210191\n",
      "Recall: 0.9854587674155892\n",
      "F1 Score: 0.9832808517019043\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1018   10]\n",
      " [   6  304]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9680072615556486\n",
      "Recall: 0.9797827802097119\n",
      "F1 Score: 0.973729328044119\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1016   18]\n",
      " [   7  297]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9712360289283366\n",
      "Recall: 0.9880153826755769\n",
      "F1 Score: 0.9792848472838069\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1012   18]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9857997010463379\n",
      "Precision: 0.9723728777060305\n",
      "Recall: 0.9884900234144356\n",
      "F1 Score: 0.980123829278533\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   17]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9835452505609573\n",
      "Precision: 0.9692390942390943\n",
      "Recall: 0.987041803223039\n",
      "F1 Score: 0.9777348835801012\n",
      "\n",
      "Confusion Matrix:\n",
      "[[999  20]\n",
      " [  2 316]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.984750903624897\n",
      "Mean Macro Precision across all folds: 0.9724004016100259\n",
      "Mean Macro Recall across all folds: 0.9857577513876704\n",
      "Mean Macro F1 Score across all folds: 0.9788307479776929\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "X_full_5 = df_full[['distance', 'radius_earth', 'orbital_radius', 'eccentricity', 'mass_earth']]\n",
    "y_full_5 = df_full['Habitable']\n",
    "\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    rf_5.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_5.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_4 = df_train[['distance', 'radius_earth', 'orbital_radius', 'eccentricity']]\n",
    "y_train_4 = df_train['Habitable']\n",
    "\n",
    "X_test_4 = df_test[['distance', 'radius_earth', 'orbital_radius', 'eccentricity']]\n",
    "y_test_4 = df_test['Habitable']\n",
    "\n",
    "X_val_4 = df_val[['distance', 'radius_earth', 'orbital_radius', 'eccentricity']]\n",
    "y_val_4 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with fewer features\n",
    "rf_4 = model.fit(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for train set\n",
    "y_train_pred_4 = rf_4.predict(X_train_4)\n",
    "print(classification_report(y_train_4, y_train_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.35      0.43      0.39        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.67      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for validation set\n",
    "y_val_pred_4 = rf_4.predict(X_val_4)\n",
    "print(classification_report(y_val_4, y_val_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9722699290890673\n",
      "Recall: 0.9754487259947282\n",
      "F1 Score: 0.9738471437875433\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1014   14]\n",
      " [  11  299]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9695119675557324\n",
      "Recall: 0.9802663392039093\n",
      "F1 Score: 0.9747516204817572\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   17]\n",
      " [   7  297]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9712360289283366\n",
      "Recall: 0.9880153826755769\n",
      "F1 Score: 0.9792848472838069\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1012   18]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9865470852017937\n",
      "Precision: 0.9747981124129901\n",
      "Recall: 0.9878124045607248\n",
      "F1 Score: 0.9811064390611272\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1019   15]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9827973074046372\n",
      "Precision: 0.9686522477433194\n",
      "Recall: 0.9854694761790138\n",
      "F1 Score: 0.9766987216159877\n",
      "\n",
      "Confusion Matrix:\n",
      "[[999  20]\n",
      " [  3 315]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9835549771759947\n",
      "Mean Macro Precision across all folds: 0.9712936571458892\n",
      "Mean Macro Recall across all folds: 0.9834024657227907\n",
      "Mean Macro F1 Score across all folds: 0.9771377544460444\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "X_full_4 = df_full[['distance', 'radius_earth', 'orbital_radius', 'eccentricity']]\n",
    "y_full_4 = df_full['Habitable']\n",
    "\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_4), 1):\n",
    "    X_train = X_full_4.iloc[train_index]\n",
    "    y_train = y_full_4.iloc[train_index]\n",
    "    X_test = X_full_4.iloc[test_index]\n",
    "    y_test = y_full_4.iloc[test_index]\n",
    "\n",
    "    rf_4.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_4.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train_3 = df_train[['distance', 'radius_earth', 'orbital_radius']]\n",
    "y_train_3 = df_train['Habitable']\n",
    "\n",
    "X_test_3 = df_test[['distance', 'radius_earth', 'orbital_radius']]\n",
    "y_test_3 = df_test['Habitable']\n",
    "\n",
    "X_val_3 = df_val[['distance', 'radius_earth', 'orbital_radius']]\n",
    "y_val_3 = df_val['Habitable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with fewer features\n",
    "rf_3 = model.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       1.00      1.00      1.00      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       1.00      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for train set\n",
    "y_train_pred_3 = rf_3.predict(X_train_3)\n",
    "print(classification_report(y_train_3, y_train_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.47      0.64      0.55        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.73      0.81      0.77       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for validation set\n",
    "y_val_pred_3 = rf_3.predict(X_val_3)\n",
    "print(classification_report(y_val_3, y_val_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9685211222304928\n",
      "Recall: 0.9799548136061252\n",
      "F1 Score: 0.9740777048888132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1010   18]\n",
      " [   7  303]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9676748057713651\n",
      "Recall: 0.9825886948997251\n",
      "F1 Score: 0.9748651364915764\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1015   19]\n",
      " [   5  299]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9835575485799701\n",
      "Precision: 0.9691997224048505\n",
      "Recall: 0.9859065691589963\n",
      "F1 Score: 0.9772133320121876\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1011   19]\n",
      " [   3  305]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9653231512879185\n",
      "Recall: 0.9832663137534359\n",
      "F1 Score: 0.9739054119941492\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1013   21]\n",
      " [   4  300]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9850411368735976\n",
      "Precision: 0.9737714784388072\n",
      "Recall: 0.9858598576727708\n",
      "F1 Score: 0.9796320670785955\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1003   16]\n",
      " [   4  314]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9826584515899661\n",
      "Mean Macro Precision across all folds: 0.9688980560266869\n",
      "Mean Macro Recall across all folds: 0.9835152498182106\n",
      "Mean Macro F1 Score across all folds: 0.9759387304930645\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "X_full_3 = df_full[['distance', 'radius_earth', 'orbital_radius']]\n",
    "y_full_3 = df_full['Habitable']\n",
    "\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_3), 1):\n",
    "    X_train = X_full_3.iloc[train_index]\n",
    "    y_train = y_full_3.iloc[train_index]\n",
    "    X_test = X_full_3.iloc[test_index]\n",
    "    y_test = y_full_3.iloc[test_index]\n",
    "\n",
    "    rf_3.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_3.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assessing accuracy, precision, recall, and F1 score, the model with 5 features achieves comparable results to the full dataset using fewer features compared to when all features are utilized. It scores better for the macro average, but a little worse at the cross validation. Based on the results, to reduce model complexity, we will use the 5 feature set for further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Parameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning class_weight, n_estimators, max_features, max_depth, max_leaf_nodes, max_samples and min_samples_split for the selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Class weight\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 10}}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for class weights\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}, {0: 1, 1: 5}, {0: 1, 1: 10}],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with class weight: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.39      0.50      0.44        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: {0: 1, 1: 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: {0: 1, 1: 3}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: {0: 1, 1: 4}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: {0: 1, 1: 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with class weight: {0: 1, 1: 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each class weight setting from the param_grid\n",
    "for i in param_grid['class_weight']:  \n",
    "    print(f\"Evaluating model with class weight: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=i)\n",
    "    model.fit(X_train_5, y_train_5)  # Training the model with the specified class weight\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output {0: 1, 1: 2} performes best at macro avg for f1-score\n",
    "class_weight_best = {0: 1, 1: 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9887892376681614\n",
      "Precision: 0.9806909784123315\n",
      "Recall: 0.988198192544245\n",
      "F1 Score: 0.9843779554036162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   11]\n",
      " [   4  306]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9835575485799701\n",
      "Precision: 0.9688390225933203\n",
      "Recall: 0.9858781685839357\n",
      "F1 Score: 0.9770111710901185\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1015   19]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9712360289283366\n",
      "Recall: 0.9880153826755769\n",
      "F1 Score: 0.9792848472838069\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1012   18]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9865470852017937\n",
      "Precision: 0.9747981124129901\n",
      "Recall: 0.9878124045607248\n",
      "F1 Score: 0.9811064390611272\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1019   15]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9857890800299177\n",
      "Precision: 0.9734784585382195\n",
      "Recall: 0.9885138346263755\n",
      "F1 Score: 0.9807110700067503\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1002   17]\n",
      " [   2  316]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9859470536741449\n",
      "Mean Macro Precision across all folds: 0.9738085201770396\n",
      "Mean Macro Recall across all folds: 0.9876835965981716\n",
      "Mean Macro F1 Score across all folds: 0.9804982965690838\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Number of trees in the forest\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for n_estimators. Using the best value from class_weight\n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [50, 100, 150, 200, 250, 300, 350, 400, 450, 500], \n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with n_estimarot: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.43      0.43      0.43        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.71      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 200\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.43      0.43      0.43        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.71      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.70      0.74      0.72       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 350\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.39      0.50      0.44        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 450\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with n_estimarot: 500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.50      0.47        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.74      0.73       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each n_estimators setting from the param_grid\n",
    "for i in param_grid['n_estimators']:  \n",
    "    print(f\"Evaluating model with n_estimarot: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output 100 gives the best macro avg for f1-score with the lowest complexity\n",
    "n_estimators_best = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9895366218236173\n",
      "Precision: 0.9822202680274468\n",
      "Recall: 0.9886845738672022\n",
      "F1 Score: 0.9854032572274605\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1018   10]\n",
      " [   4  306]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9790732436472347\n",
      "Precision: 0.9653506916799364\n",
      "Recall: 0.9760097475313041\n",
      "F1 Score: 0.9705435572287167\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1015   19]\n",
      " [   9  295]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.984304932735426\n",
      "Precision: 0.9697820639380363\n",
      "Recall: 0.987529945782373\n",
      "F1 Score: 0.9782728215406671\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1011   19]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9872944693572496\n",
      "Precision: 0.9753612620768282\n",
      "Recall: 0.9894571414028301\n",
      "F1 Score: 0.9821761463145151\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1019   15]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9865370231862378\n",
      "Precision: 0.9749085895822094\n",
      "Recall: 0.989004511760821\n",
      "F1 Score: 0.9817072058376406\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1003   16]\n",
      " [   2  316]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9853492581499532\n",
      "Mean Macro Precision across all folds: 0.9735245750608914\n",
      "Mean Macro Recall across all folds: 0.9861371840689062\n",
      "Mean Macro F1 Score across all folds: 0.9796205976297999\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 \n",
    "max_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'max_features': 'sqrt', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid. \n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [n_estimators_best], \n",
    "    'max_features': [None, 'sqrt', 'log2', 0.25, 0.5, 0.75, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with max features: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.35      0.43      0.39        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.67      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: sqrt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.39      0.50      0.44        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: log2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.43      0.43      0.43        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.71      0.71      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.57      0.50        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.72      0.78      0.74       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.47      0.50      0.48        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.73      0.74      0.74       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.39      0.50      0.44        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max features: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.33      0.43      0.38        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.66      0.71      0.68       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each setting from the param_grid\n",
    "for i in param_grid['max_features']:  \n",
    "    print(f\"Evaluating model with max features: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_features = i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output 0.5 gives the best macro avg for f1-score\n",
    "max_features_best = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9872944693572496\n",
      "Precision: 0.9796071312200345\n",
      "Recall: 0.984972386092632\n",
      "F1 Score: 0.9822556801560214\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   11]\n",
      " [   6  304]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9798206278026906\n",
      "Precision: 0.9659312014150724\n",
      "Recall: 0.9776544843734094\n",
      "F1 Score: 0.9716276742876486\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1015   19]\n",
      " [   8  296]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.984304932735426\n",
      "Precision: 0.9706583903979015\n",
      "Recall: 0.9863920060522002\n",
      "F1 Score: 0.9782252721066029\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1012   18]\n",
      " [   3  305]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9872944693572496\n",
      "Precision: 0.9763115021179538\n",
      "Recall: 0.9882959635549222\n",
      "F1 Score: 0.982135943070001\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1020   14]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9827973074046372\n",
      "Precision: 0.9686522477433194\n",
      "Recall: 0.9854694761790138\n",
      "F1 Score: 0.9766987216159877\n",
      "\n",
      "Confusion Matrix:\n",
      "[[999  20]\n",
      " [  3 315]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9843023613314508\n",
      "Mean Macro Precision across all folds: 0.9722320945788564\n",
      "Mean Macro Recall across all folds: 0.9845568632504355\n",
      "Mean Macro F1 Score across all folds: 0.9781886582472523\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best,max_features=max_features_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 The maximum depth of each tree\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'max_depth': 30, 'max_features': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid. \n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [n_estimators_best], \n",
    "    'max_features': [max_features_best],\n",
    "    'max_depth': [2, 5, 8, 10, 30]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with max_depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91       767\n",
      "           1       0.07      0.71      0.13        14\n",
      "\n",
      "    accuracy                           0.83       781\n",
      "   macro avg       0.53      0.77      0.52       781\n",
      "weighted avg       0.98      0.83      0.89       781\n",
      "\n",
      "Evaluating model with max_depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       767\n",
      "           1       0.12      0.43      0.18        14\n",
      "\n",
      "    accuracy                           0.93       781\n",
      "   macro avg       0.55      0.68      0.57       781\n",
      "weighted avg       0.97      0.93      0.95       781\n",
      "\n",
      "Evaluating model with max_depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.26      0.57      0.36        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.77      0.67       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n",
      "Evaluating model with max_depth: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       767\n",
      "           1       0.30      0.57      0.39        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.64      0.77      0.69       781\n",
      "weighted avg       0.98      0.97      0.97       781\n",
      "\n",
      "Evaluating model with max_depth: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.44      0.57      0.50        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.72      0.78      0.74       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each setting from the param_grid\n",
    "for i in param_grid['max_depth']:  \n",
    "    print(f\"Evaluating model with max_depth: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_depth=i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output 30 gives the best macro avg for f1-score with the lowest complexity\n",
    "max_depth_best = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9880418535127056\n",
      "Precision: 0.9791712911579726\n",
      "Recall: 0.9877118112212878\n",
      "F1 Score: 0.9833548964968153\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1016   12]\n",
      " [   4  306]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9695119675557324\n",
      "Recall: 0.9802663392039093\n",
      "F1 Score: 0.9747516204817572\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1017   17]\n",
      " [   7  297]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9835575485799701\n",
      "Precision: 0.9683370110817431\n",
      "Recall: 0.9870445088891691\n",
      "F1 Score: 0.9772629666591484\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1010   20]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9880418535127056\n",
      "Precision: 0.9778345193073248\n",
      "Recall: 0.9887795225491194\n",
      "F1 Score: 0.9831677469878382\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021   13]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9850411368735976\n",
      "Precision: 0.9712266899766899\n",
      "Recall: 0.9891048074015096\n",
      "F1 Score: 0.9797589850728192\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1000   19]\n",
      " [   1  317]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9853490345496075\n",
      "Mean Macro Precision across all folds: 0.9732162958158925\n",
      "Mean Macro Recall across all folds: 0.986581397852999\n",
      "Mean Macro F1 Score across all folds: 0.9796592431396757\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best,max_features=max_features_best,max_depth=max_depth_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 \n",
    "max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'max_depth': 30, 'max_features': 0.5, 'max_leaf_nodes': 100, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [n_estimators_best], \n",
    "    'max_features': [max_features_best],\n",
    "    'max_depth': [max_depth_best],\n",
    "    'max_leaf_nodes': [None, 20, 40, 60, 80, 100]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with max_leaf_nodes: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.38      0.43      0.40        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.71      0.69       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max_leaf_nodes: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.21      0.50      0.30        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.60      0.73      0.64       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n",
      "Evaluating model with max_leaf_nodes: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.26      0.57      0.36        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.77      0.67       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n",
      "Evaluating model with max_leaf_nodes: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       767\n",
      "           1       0.30      0.50      0.38        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.65      0.74      0.68       781\n",
      "weighted avg       0.98      0.97      0.97       781\n",
      "\n",
      "Evaluating model with max_leaf_nodes: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.37      0.50      0.42        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max_leaf_nodes: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.40      0.43      0.41        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.71      0.70       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each setting from the param_grid\n",
    "for i in param_grid['max_leaf_nodes']:  \n",
    "    print(f\"Evaluating model with max_leaf_nodes: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_depth=max_depth_best, max_leaf_nodes=i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output 80 gives the best macro avg for f1-score\n",
    "max_leaf_nodes_best = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9857997010463379\n",
      "Precision: 0.9746689456804418\n",
      "Recall: 0.9862526672524162\n",
      "F1 Score: 0.980299055715498\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1013   15]\n",
      " [   4  306]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9798206278026906\n",
      "Precision: 0.9615961728301313\n",
      "Recall: 0.9834603736129492\n",
      "F1 Score: 0.9719423437921095\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1010   24]\n",
      " [   3  301]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9654733156242454\n",
      "Recall: 0.9860736351027614\n",
      "F1 Score: 0.9752497225305217\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   22]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9790732436472347\n",
      "Precision: 0.9593757546486357\n",
      "Recall: 0.9841379924666599\n",
      "F1 Score: 0.9709987861973296\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   26]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9745699326851159\n",
      "Precision: 0.9536886895352974\n",
      "Recall: 0.9800720277001129\n",
      "F1 Score: 0.9659398789186597\n",
      "\n",
      "Confusion Matrix:\n",
      "[[988  31]\n",
      " [  3 315]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9802652570900874\n",
      "Mean Macro Precision across all folds: 0.9629605756637503\n",
      "Mean Macro Recall across all folds: 0.9839993392269799\n",
      "Mean Macro F1 Score across all folds: 0.9728859574308238\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_features=max_features_best, max_depth=max_depth_best, \n",
    "                                   max_leaf_nodes=max_leaf_nodes_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 \n",
    "max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'max_depth': 30, 'max_features': 0.5, 'max_leaf_nodes': 80, 'max_samples': 0.85, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid.\n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [n_estimators_best], \n",
    "    'max_features': [max_features_best],\n",
    "    'max_depth': [max_depth_best],\n",
    "    'max_leaf_nodes': [max_leaf_nodes_best],\n",
    "    'max_samples': [0.85, 0.9, 0.95, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with max_samples: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.36      0.57      0.44        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.68      0.78      0.72       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with max_samples: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.35      0.50      0.41        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.67      0.74      0.70       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with max_samples: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.37      0.50      0.42        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with max_samples: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       767\n",
      "           1       0.39      0.50      0.44        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.69      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each setting from the param_grid\n",
    "for i in param_grid['max_samples']:  \n",
    "    print(f\"Evaluating model with max_samples: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_depth=max_depth_best, max_leaf_nodes= max_leaf_nodes_best,max_samples =i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The automatically output gives the best macro avg for f1-score with the lowest complexity\n",
    "max_samples_best = best_params['max_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9750462449130596\n",
      "Recall: 0.9835132421237605\n",
      "F1 Score: 0.9791936206210191\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1014   14]\n",
      " [   6  304]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9775784753363229\n",
      "Precision: 0.9589542698517057\n",
      "Recall: 0.9796873409345414\n",
      "F1 Score: 0.9687904309315287\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1009   25]\n",
      " [   5  299]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9654733156242454\n",
      "Recall: 0.9860736351027614\n",
      "F1 Score: 0.9752497225305217\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   22]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9790732436472347\n",
      "Precision: 0.9593757546486357\n",
      "Recall: 0.9841379924666599\n",
      "F1 Score: 0.9709987861973296\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   26]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9775617053103964\n",
      "Precision: 0.9575879446813227\n",
      "Recall: 0.9841980360570544\n",
      "F1 Score: 0.9699469519870527\n",
      "\n",
      "Confusion Matrix:\n",
      "[[990  29]\n",
      " [  1 317]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9802657042907787\n",
      "Mean Macro Precision across all folds: 0.9632875059437938\n",
      "Mean Macro Recall across all folds: 0.9835220493369554\n",
      "Mean Macro F1 Score across all folds: 0.9728359024534903\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_features=max_features_best, max_depth=max_depth_best, \n",
    "                                   max_leaf_nodes=max_leaf_nodes_best, max_samples=max_samples_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7\n",
    "min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 2}, 'max_depth': 30, 'max_features': 0.5, 'max_leaf_nodes': 80, 'max_samples': 0.85, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'class_weight': [class_weight_best],\n",
    "    'n_estimators' : [n_estimators_best], \n",
    "    'max_features': [max_features_best],\n",
    "    'max_depth': [max_depth_best],\n",
    "    'max_leaf_nodes': [max_leaf_nodes_best],\n",
    "    'max_samples': [max_samples_best],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 50]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the RandomForest model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with min_samples_split: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.37      0.50      0.42        14\n",
      "\n",
      "    accuracy                           0.98       781\n",
      "   macro avg       0.68      0.74      0.71       781\n",
      "weighted avg       0.98      0.98      0.98       781\n",
      "\n",
      "Evaluating model with min_samples_split: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.35      0.50      0.41        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.67      0.74      0.70       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with min_samples_split: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.36      0.57      0.44        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.68      0.78      0.72       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with min_samples_split: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.35      0.57      0.43        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.67      0.78      0.71       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with min_samples_split: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.33      0.57      0.42        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.66      0.78      0.70       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n",
      "Evaluating model with min_samples_split: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       767\n",
      "           1       0.26      0.57      0.36        14\n",
      "\n",
      "    accuracy                           0.96       781\n",
      "   macro avg       0.63      0.77      0.67       781\n",
      "weighted avg       0.98      0.96      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each setting from the param_grid\n",
    "for i in param_grid['min_samples_split']:  \n",
    "    print(f\"Evaluating model with min_samples_split: {i}\")\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_depth=max_depth_best, max_leaf_nodes= max_leaf_nodes_best,max_samples=max_samples_best, min_samples_split= i)\n",
    "    model.fit(X_train_5, y_train_5)  # Train the model with the parameters\n",
    "    predictions = model.predict(X_val_5)  \n",
    "    print(classification_report(y_val_5, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the manually output 10 gives the best scores for f1 macro avg.\n",
    "min_samples_split_best = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9741067043222004\n",
      "Recall: 0.9846397640266098\n",
      "F1 Score: 0.9792393985942374\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1013   15]\n",
      " [   5  305]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9775784753363229\n",
      "Precision: 0.9589542698517057\n",
      "Recall: 0.9796873409345414\n",
      "F1 Score: 0.9687904309315287\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1009   25]\n",
      " [   5  299]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9654733156242454\n",
      "Recall: 0.9860736351027614\n",
      "F1 Score: 0.9752497225305217\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   22]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9636282177841902\n",
      "Recall: 0.9855886694492517\n",
      "F1 Score: 0.9740206886963978\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1011   23]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9798055347793567\n",
      "Precision: 0.9623390924401418\n",
      "Recall: 0.9845884175508113\n",
      "F1 Score: 0.9728146639204449\n",
      "\n",
      "Confusion Matrix:\n",
      "[[994  25]\n",
      " [  2 316]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9811629006778444\n",
      "Mean Macro Precision across all folds: 0.9649003200044965\n",
      "Mean Macro Recall across all folds: 0.9841155654127951\n",
      "Mean Macro F1 Score across all folds: 0.974022980934626\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model = RandomForestClassifier(class_weight=class_weight_best, n_estimators=n_estimators_best, max_features=max_features_best, max_depth=max_depth_best, \n",
    "                                   max_leaf_nodes=max_leaf_nodes_best, max_samples=max_samples_best, min_samples_split =min_samples_split_best)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Best Model based on individual performance\n",
    "\n",
    "When individually tuning the individual parameters of the random forest, the following parameters produced the best performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight_best:  {0: 1, 1: 2} \n",
      " n_estimators_best:  100 \n",
      " max_features_best:  0.5 \n",
      " max_depth_best:  30 \n",
      " max_leaf_nodes_best:  80 \n",
      " max_samples_best:  0.85 \n",
      " min_samples_split_best:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"class_weight_best: \", class_weight_best, \"\\n n_estimators_best: \", n_estimators_best,\n",
    "      \"\\n max_features_best: \", max_features_best, \"\\n max_depth_best: \", max_depth_best,\n",
    "      \"\\n max_leaf_nodes_best: \", max_leaf_nodes_best, \"\\n max_samples_best: \", max_samples_best,\n",
    "      \"\\n min_samples_split_best: \", min_samples_split_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       0.98      1.00      0.99      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       0.99      1.00      0.99      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       767\n",
      "           1       0.30      0.50      0.38        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.65      0.74      0.68       781\n",
      "weighted avg       0.98      0.97      0.97       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_best_features = RandomForestClassifier(class_weight=class_weight_best, \n",
    "                                             n_estimators=n_estimators_best,\n",
    "                                             max_features= max_features_best, \n",
    "                                             max_depth= max_depth_best,\n",
    "                                             max_leaf_nodes= max_leaf_nodes_best,\n",
    "                                             max_samples= max_samples_best,\n",
    "                                             min_samples_split= min_samples_split_best\n",
    "                                             )\n",
    "                                            \n",
    "\n",
    "# Fit the model\n",
    "model_best_features.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_best_features = model_best_features.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with best features:\")\n",
    "print(classification_report(y_train_5, model_best_features.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with best features:\")\n",
    "print(classification_report(y_val_5, y_val_pred_best_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.984304932735426\n",
      "Precision: 0.9735449654064929\n",
      "Recall: 0.9830268608008033\n",
      "F1 Score: 0.9781773785049741\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1013   15]\n",
      " [   6  304]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9775784753363229\n",
      "Precision: 0.9589542698517057\n",
      "Recall: 0.9796873409345414\n",
      "F1 Score: 0.9687904309315287\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1009   25]\n",
      " [   5  299]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9820627802690582\n",
      "Precision: 0.9654733156242454\n",
      "Recall: 0.9860736351027614\n",
      "F1 Score: 0.9752497225305217\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1008   22]\n",
      " [   2  306]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9813153961136024\n",
      "Precision: 0.9636282177841902\n",
      "Recall: 0.9855886694492517\n",
      "F1 Score: 0.9740206886963978\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1011   23]\n",
      " [   2  302]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9790575916230366\n",
      "Precision: 0.9609832789679391\n",
      "Recall: 0.9840977404163658\n",
      "F1 Score: 0.9718365381721885\n",
      "\n",
      "Confusion Matrix:\n",
      "[[993  26]\n",
      " [  2 316]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9808638352154893\n",
      "Mean Macro Precision across all folds: 0.9645168095269145\n",
      "Mean Macro Recall across all folds: 0.9836948493407446\n",
      "Mean Macro F1 Score across all folds: 0.9736149517671221\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model_best_features.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_best_features.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Best Model based on Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'class_weight': {0: 1, 1: 10}, 'max_depth': 30, 'max_features': 0.5, 'max_leaf_nodes': 80, 'max_samples': 0.85, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'class_weight': [None, {0: 1, 1: 2}, {0: 1, 1: 10}],\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'max_features': [0.25, 0.5, 0.75],\n",
    "    'max_depth': [5, 10, 30],\n",
    "    'max_leaf_nodes': [10, 40, 80],\n",
    "    'max_samples': [0.75, 0.85, 0.95],\n",
    "    'min_samples_split': [5, 10, 15]\n",
    "}\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_5, param_grid=param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store each parameter in a separate variable\n",
    "class_weight_best_grid = best_params['class_weight']\n",
    "n_estimators_best_grid = best_params['n_estimators']\n",
    "max_features_best_grid = best_params['max_features']\n",
    "max_depth_best_grid = best_params['max_depth']\n",
    "max_leaf_nodes_best_grid = best_params['max_leaf_nodes']\n",
    "max_samples_best_grid = best_params['max_samples']\n",
    "min_samples_split_best_grid = best_params['min_samples_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3608\n",
      "           1       0.99      1.00      0.99      1082\n",
      "\n",
      "    accuracy                           1.00      4690\n",
      "   macro avg       0.99      1.00      1.00      4690\n",
      "weighted avg       1.00      1.00      1.00      4690\n",
      "\n",
      "Validation set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       767\n",
      "           1       0.35      0.50      0.41        14\n",
      "\n",
      "    accuracy                           0.97       781\n",
      "   macro avg       0.67      0.74      0.70       781\n",
      "weighted avg       0.98      0.97      0.98       781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_best_grid_search_features = RandomForestClassifier(class_weight=class_weight_best_grid, \n",
    "                                            n_estimators=n_estimators_best_grid,\n",
    "                                            max_features= max_features_best_grid, \n",
    "                                            max_depth= max_depth_best_grid,\n",
    "                                            max_leaf_nodes= max_leaf_nodes_best_grid,\n",
    "                                            max_samples= max_samples_best_grid,\n",
    "                                            min_samples_split= min_samples_split_best_grid\n",
    "                                            )                                        \n",
    "\n",
    "# Fit the model on the training data\n",
    "model_best_grid_search_features.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_best_features = model_best_grid_search_features.predict(X_val_5)\n",
    "\n",
    "# Print classification report for train set \n",
    "print(\"Training set classification report with best features:\")\n",
    "print(classification_report(y_train_5, model_best_grid_search_features.predict(X_train_5))) \n",
    "\n",
    "# Print classification report for validation set \n",
    "print(\"Validation set classification report with best features:\")\n",
    "print(classification_report(y_val_5, y_val_pred_best_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1, we look on the macro avg:\n",
      "Accuracy: 0.9850523168908819\n",
      "Precision: 0.9731867755660977\n",
      "Recall: 0.985766285929459\n",
      "F1 Score: 0.9792848472838069\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1012   16]\n",
      " [   4  306]]\n",
      "\n",
      "For fold 2, we look on the macro avg:\n",
      "Accuracy: 0.9753363228699552\n",
      "Precision: 0.955500037967955\n",
      "Recall: 0.9770754861040416\n",
      "F1 Score: 0.9657073090792451\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1007   27]\n",
      " [   6  298]]\n",
      "\n",
      "For fold 3, we look on the macro avg:\n",
      "Accuracy: 0.9790732436472347\n",
      "Precision: 0.9606331168831168\n",
      "Recall: 0.9829939477997731\n",
      "F1 Score: 0.9711869464500509\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1005   25]\n",
      " [   3  305]]\n",
      "\n",
      "For fold 4, we look on the macro avg:\n",
      "Accuracy: 0.9775784753363229\n",
      "Precision: 0.9558282833121752\n",
      "Recall: 0.9843320523261733\n",
      "F1 Score: 0.969062153163152\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1005   29]\n",
      " [   1  303]]\n",
      "\n",
      "For fold 5, we look on the macro avg:\n",
      "Accuracy: 0.9798055347793567\n",
      "Precision: 0.9615961072557796\n",
      "Recall: 0.9856700674603909\n",
      "F1 Score: 0.9728699910491037\n",
      "\n",
      "Confusion Matrix:\n",
      "[[993  26]\n",
      " [  1 317]]\n",
      "\n",
      "Mean Macro Accuracy across all folds: 0.9793691787047504\n",
      "Mean Macro Precision across all folds: 0.9613488641970248\n",
      "Mean Macro Recall across all folds: 0.9831675679239676\n",
      "Mean Macro F1 Score across all folds: 0.9716222494050717\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "# Initialize KFold with shuffling and random_state for targeted reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store evaluation metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_precisions = []\n",
    "fold_recalls = []\n",
    "fold_f1_scores = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_full_5), 1):\n",
    "    X_train = X_full_5.iloc[train_index]\n",
    "    y_train = y_full_5.iloc[train_index]\n",
    "    X_test = X_full_5.iloc[test_index]\n",
    "    y_test = y_full_5.iloc[test_index]\n",
    "\n",
    "    model_best_grid_search_features.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_best_grid_search_features.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    print(f'For fold {fold}, we look on the macro avg:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print()\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix:\\n{cm}\\n')\n",
    "\n",
    "# Mean evaluation metrics across all folds\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "mean_precision = sum(fold_precisions) / len(fold_precisions)\n",
    "mean_recall = sum(fold_recalls) / len(fold_recalls)\n",
    "mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
    "\n",
    "print(f'Mean Macro Accuracy across all folds: {mean_accuracy}')\n",
    "print(f'Mean Macro Precision across all folds: {mean_precision}')\n",
    "print(f'Mean Macro Recall across all folds: {mean_recall}')\n",
    "print(f'Mean Macro F1 Score across all folds: {mean_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[757  13]\n",
      " [  0  12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       770\n",
      "           1       0.48      1.00      0.65        12\n",
      "\n",
      "    accuracy                           0.98       782\n",
      "   macro avg       0.74      0.99      0.82       782\n",
      "weighted avg       0.99      0.98      0.99       782\n",
      "\n",
      "Confusion Matrix:\n",
      ", [[757  13]\n",
      " [  0  12]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_best_grid_search_features.predict(X_test_5)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_5, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix with adjusted normalization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False, \n",
    "            xticklabels=['Not Habitable', 'Habitable'], yticklabels=['Not Habitable', 'Habitable'],\n",
    "            annot_kws={\"size\": 12})\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for test set \n",
    "print(\"Test set classification report with best features:\")\n",
    "print(classification_report(y_test_5, model_best_grid_search_features.predict(X_test_5))) \n",
    "print(f'Confusion Matrix:\\n,', confusion_matrix(y_test_5, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Evaluate the test set on the model performed second best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[759  11]\n",
      " [  0  12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set classification report with best features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       770\n",
      "           1       0.52      1.00      0.69        12\n",
      "\n",
      "    accuracy                           0.99       782\n",
      "   macro avg       0.76      0.99      0.84       782\n",
      "weighted avg       0.99      0.99      0.99       782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_best_features.predict(X_test_5)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_5, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix with adjusted normalization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', cbar=False, \n",
    "            xticklabels=['Not Habitable', 'Habitable'], yticklabels=['Not Habitable', 'Habitable'],\n",
    "            annot_kws={\"size\": 12})\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report for test set \n",
    "print(\"Test set classification report with best features:\")\n",
    "print(classification_report(y_test_5, model_best_features.predict(X_test_5))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       770\n",
      "           1       0.25      0.25      0.25        12\n",
      "\n",
      "    accuracy                           0.98       782\n",
      "   macro avg       0.62      0.62      0.62       782\n",
      "weighted avg       0.98      0.98      0.98       782\n",
      "\n",
      "Random Forest training time: 0.93 seconds\n",
      "Random Forest prediction time: 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "training_times = {}\n",
    "\n",
    "# Start measuring time for training\n",
    "start_time = time.time()\n",
    "model_best_grid_search_features.fit(X_train_5, y_train_5)  \n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training duration\n",
    "training_duration = end_time - start_time\n",
    "\n",
    "# Start measuring time for prediction\n",
    "start_time = time.time()\n",
    "predictions = model_best_grid_search_features.predict(X_test_5)\n",
    "prediction_time = time.time() - start_time\n",
    "\n",
    "\n",
    "training_times['Random Forest'] = {'Training Time': training_duration, 'Prediction Time': prediction_time}\n",
    "\n",
    "print(classification_report(y_test_5, predictions))\n",
    "print(f\"Random Forest training time: {training_duration:.2f} seconds\")\n",
    "print(f\"Random Forest prediction time: {prediction_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
